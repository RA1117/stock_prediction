{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d62743a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import yfinance as yf\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "656d05b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "start = '2016-01-03'\n",
    "end = '2023-01-01'\n",
    "\n",
    "df = data.get_data_yahoo('^N225', start, end)\n",
    "df.to_csv('finance_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "93d3d87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>18818.580078</td>\n",
       "      <td>18951.119141</td>\n",
       "      <td>18394.429688</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>140200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>18398.759766</td>\n",
       "      <td>18547.380859</td>\n",
       "      <td>18327.519531</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>132300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>18410.570312</td>\n",
       "      <td>18469.380859</td>\n",
       "      <td>18064.300781</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>142200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>18139.769531</td>\n",
       "      <td>18172.039062</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>168000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>17562.230469</td>\n",
       "      <td>17975.310547</td>\n",
       "      <td>17509.640625</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>184300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>26299.539062</td>\n",
       "      <td>26438.650391</td>\n",
       "      <td>26294.849609</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>47300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>26570.779297</td>\n",
       "      <td>26620.490234</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>50200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>26309.339844</td>\n",
       "      <td>26354.269531</td>\n",
       "      <td>26199.669922</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>61500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>26074.900391</td>\n",
       "      <td>26126.699219</td>\n",
       "      <td>25953.919922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>63100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>26288.000000</td>\n",
       "      <td>26321.369141</td>\n",
       "      <td>26067.919922</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>52700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2016-01-04  18818.580078  18951.119141  18394.429688  18450.980469   \n",
       "1     2016-01-05  18398.759766  18547.380859  18327.519531  18374.000000   \n",
       "2     2016-01-06  18410.570312  18469.380859  18064.300781  18191.320312   \n",
       "3     2016-01-07  18139.769531  18172.039062  17767.339844  17767.339844   \n",
       "4     2016-01-08  17562.230469  17975.310547  17509.640625  17697.960938   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "1705  2022-12-26  26299.539062  26438.650391  26294.849609  26405.869141   \n",
       "1706  2022-12-27  26570.779297  26620.490234  26447.869141  26447.869141   \n",
       "1707  2022-12-28  26309.339844  26354.269531  26199.669922  26340.500000   \n",
       "1708  2022-12-29  26074.900391  26126.699219  25953.919922  26093.669922   \n",
       "1709  2022-12-30  26288.000000  26321.369141  26067.919922  26094.500000   \n",
       "\n",
       "         Adj Close     Volume  \n",
       "0     18450.980469  140200000  \n",
       "1     18374.000000  132300000  \n",
       "2     18191.320312  142200000  \n",
       "3     17767.339844  168000000  \n",
       "4     17697.960938  184300000  \n",
       "...            ...        ...  \n",
       "1705  26405.869141   47300000  \n",
       "1706  26447.869141   50200000  \n",
       "1707  26340.500000   61500000  \n",
       "1708  26093.669922   63100000  \n",
       "1709  26094.500000   52700000  \n",
       "\n",
       "[1710 rows x 7 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('finance_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "042c0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1710 entries, 0 to 1709\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       1710 non-null   object \n",
      " 1   Open       1710 non-null   float64\n",
      " 2   High       1710 non-null   float64\n",
      " 3   Low        1710 non-null   float64\n",
      " 4   Close      1710 non-null   float64\n",
      " 5   Adj Close  1710 non-null   float64\n",
      " 6   Volume     1710 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 93.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e16bea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1710 entries, 0 to 1709\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       1710 non-null   datetime64[ns]\n",
      " 1   Open       1710 non-null   float64       \n",
      " 2   High       1710 non-null   float64       \n",
      " 3   Low        1710 non-null   float64       \n",
      " 4   Close      1710 non-null   float64       \n",
      " 5   Adj Close  1710 non-null   float64       \n",
      " 6   Volume     1710 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1)\n",
      "memory usage: 93.6 KB\n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3969db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1710 entries, 0 to 1709\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       1710 non-null   object \n",
      " 1   Open       1710 non-null   float64\n",
      " 2   High       1710 non-null   float64\n",
      " 3   Low        1710 non-null   float64\n",
      " 4   Close      1710 non-null   float64\n",
      " 5   Adj Close  1710 non-null   float64\n",
      " 6   Volume     1710 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 93.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_b = pd.read_csv('finance_dataset.csv')\n",
    "df_b.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76069e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df_b['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ece1983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>delta_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>18818.580078</td>\n",
       "      <td>18951.119141</td>\n",
       "      <td>18394.429688</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>140200000</td>\n",
       "      <td>-24.759766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>18398.759766</td>\n",
       "      <td>18547.380859</td>\n",
       "      <td>18327.519531</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>132300000</td>\n",
       "      <td>-219.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>18410.570312</td>\n",
       "      <td>18469.380859</td>\n",
       "      <td>18064.300781</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>142200000</td>\n",
       "      <td>-372.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>18139.769531</td>\n",
       "      <td>18172.039062</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>168000000</td>\n",
       "      <td>135.730469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>17562.230469</td>\n",
       "      <td>17975.310547</td>\n",
       "      <td>17509.640625</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>184300000</td>\n",
       "      <td>-251.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>26299.539062</td>\n",
       "      <td>26438.650391</td>\n",
       "      <td>26294.849609</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>47300000</td>\n",
       "      <td>-122.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>26570.779297</td>\n",
       "      <td>26620.490234</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>50200000</td>\n",
       "      <td>31.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>26309.339844</td>\n",
       "      <td>26354.269531</td>\n",
       "      <td>26199.669922</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>61500000</td>\n",
       "      <td>18.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>26074.900391</td>\n",
       "      <td>26126.699219</td>\n",
       "      <td>25953.919922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>63100000</td>\n",
       "      <td>-193.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>26288.000000</td>\n",
       "      <td>26321.369141</td>\n",
       "      <td>26067.919922</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>52700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  \\\n",
       "0    2016-01-04  18818.580078  18951.119141  18394.429688  18450.980469   \n",
       "1    2016-01-05  18398.759766  18547.380859  18327.519531  18374.000000   \n",
       "2    2016-01-06  18410.570312  18469.380859  18064.300781  18191.320312   \n",
       "3    2016-01-07  18139.769531  18172.039062  17767.339844  17767.339844   \n",
       "4    2016-01-08  17562.230469  17975.310547  17509.640625  17697.960938   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "1705 2022-12-26  26299.539062  26438.650391  26294.849609  26405.869141   \n",
       "1706 2022-12-27  26570.779297  26620.490234  26447.869141  26447.869141   \n",
       "1707 2022-12-28  26309.339844  26354.269531  26199.669922  26340.500000   \n",
       "1708 2022-12-29  26074.900391  26126.699219  25953.919922  26093.669922   \n",
       "1709 2022-12-30  26288.000000  26321.369141  26067.919922  26094.500000   \n",
       "\n",
       "         Adj Close     Volume  delta_Close  \n",
       "0     18450.980469  140200000   -24.759766  \n",
       "1     18374.000000  132300000  -219.250000  \n",
       "2     18191.320312  142200000  -372.429688  \n",
       "3     17767.339844  168000000   135.730469  \n",
       "4     17697.960938  184300000  -251.968750  \n",
       "...            ...        ...          ...  \n",
       "1705  26405.869141   47300000  -122.910156  \n",
       "1706  26447.869141   50200000    31.160156  \n",
       "1707  26340.500000   61500000    18.769531  \n",
       "1708  26093.669922   63100000  -193.500000  \n",
       "1709  26094.500000   52700000          NaN  \n",
       "\n",
       "[1710 rows x 8 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shift = df.shift(-1)\n",
    "df['delta_Close'] = df_shift['Close'] - df_shift['Open']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a7b26533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>18818.580078</td>\n",
       "      <td>18951.119141</td>\n",
       "      <td>18394.429688</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>140200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>18398.759766</td>\n",
       "      <td>18547.380859</td>\n",
       "      <td>18327.519531</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>132300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>18410.570312</td>\n",
       "      <td>18469.380859</td>\n",
       "      <td>18064.300781</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>142200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>18139.769531</td>\n",
       "      <td>18172.039062</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>168000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>17562.230469</td>\n",
       "      <td>17975.310547</td>\n",
       "      <td>17509.640625</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>184300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>26299.539062</td>\n",
       "      <td>26438.650391</td>\n",
       "      <td>26294.849609</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>47300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>26570.779297</td>\n",
       "      <td>26620.490234</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>50200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>26309.339844</td>\n",
       "      <td>26354.269531</td>\n",
       "      <td>26199.669922</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>61500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>26074.900391</td>\n",
       "      <td>26126.699219</td>\n",
       "      <td>25953.919922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>63100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>26288.000000</td>\n",
       "      <td>26321.369141</td>\n",
       "      <td>26067.919922</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>52700000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  \\\n",
       "0    2016-01-04  18818.580078  18951.119141  18394.429688  18450.980469   \n",
       "1    2016-01-05  18398.759766  18547.380859  18327.519531  18374.000000   \n",
       "2    2016-01-06  18410.570312  18469.380859  18064.300781  18191.320312   \n",
       "3    2016-01-07  18139.769531  18172.039062  17767.339844  17767.339844   \n",
       "4    2016-01-08  17562.230469  17975.310547  17509.640625  17697.960938   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "1705 2022-12-26  26299.539062  26438.650391  26294.849609  26405.869141   \n",
       "1706 2022-12-27  26570.779297  26620.490234  26447.869141  26447.869141   \n",
       "1707 2022-12-28  26309.339844  26354.269531  26199.669922  26340.500000   \n",
       "1708 2022-12-29  26074.900391  26126.699219  25953.919922  26093.669922   \n",
       "1709 2022-12-30  26288.000000  26321.369141  26067.919922  26094.500000   \n",
       "\n",
       "         Adj Close     Volume  UP  \n",
       "0     18450.980469  140200000   0  \n",
       "1     18374.000000  132300000   0  \n",
       "2     18191.320312  142200000   0  \n",
       "3     17767.339844  168000000   1  \n",
       "4     17697.960938  184300000   0  \n",
       "...            ...        ...  ..  \n",
       "1705  26405.869141   47300000   0  \n",
       "1706  26447.869141   50200000   1  \n",
       "1707  26340.500000   61500000   1  \n",
       "1708  26093.669922   63100000   0  \n",
       "1709  26094.500000   52700000   0  \n",
       "\n",
       "[1710 rows x 8 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['UP'] = 0\n",
    "df['UP'] [df['delta_Close'] > 0] = 1\n",
    "df = df.drop('delta_Close', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa15ab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>18818.580078</td>\n",
       "      <td>18951.119141</td>\n",
       "      <td>18394.429688</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>18398.759766</td>\n",
       "      <td>18547.380859</td>\n",
       "      <td>18327.519531</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>18410.570312</td>\n",
       "      <td>18469.380859</td>\n",
       "      <td>18064.300781</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>18139.769531</td>\n",
       "      <td>18172.039062</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>17562.230469</td>\n",
       "      <td>17975.310547</td>\n",
       "      <td>17509.640625</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>26299.539062</td>\n",
       "      <td>26438.650391</td>\n",
       "      <td>26294.849609</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>26570.779297</td>\n",
       "      <td>26620.490234</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>26309.339844</td>\n",
       "      <td>26354.269531</td>\n",
       "      <td>26199.669922</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>26074.900391</td>\n",
       "      <td>26126.699219</td>\n",
       "      <td>25953.919922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>26288.000000</td>\n",
       "      <td>26321.369141</td>\n",
       "      <td>26067.919922</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  UP\n",
       "0    2016-01-04  18818.580078  18951.119141  18394.429688  18450.980469   0\n",
       "1    2016-01-05  18398.759766  18547.380859  18327.519531  18374.000000   0\n",
       "2    2016-01-06  18410.570312  18469.380859  18064.300781  18191.320312   0\n",
       "3    2016-01-07  18139.769531  18172.039062  17767.339844  17767.339844   1\n",
       "4    2016-01-08  17562.230469  17975.310547  17509.640625  17697.960938   0\n",
       "...         ...           ...           ...           ...           ...  ..\n",
       "1705 2022-12-26  26299.539062  26438.650391  26294.849609  26405.869141   0\n",
       "1706 2022-12-27  26570.779297  26620.490234  26447.869141  26447.869141   1\n",
       "1707 2022-12-28  26309.339844  26354.269531  26199.669922  26340.500000   1\n",
       "1708 2022-12-29  26074.900391  26126.699219  25953.919922  26093.669922   0\n",
       "1709 2022-12-30  26288.000000  26321.369141  26067.919922  26094.500000   0\n",
       "\n",
       "[1710 rows x 6 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Date', 'Open', 'High', 'Low', 'Close', 'UP']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "24985b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>18818.580078</td>\n",
       "      <td>18951.119141</td>\n",
       "      <td>18394.429688</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>18398.759766</td>\n",
       "      <td>18547.380859</td>\n",
       "      <td>18327.519531</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>18410.570312</td>\n",
       "      <td>18469.380859</td>\n",
       "      <td>18064.300781</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>18139.769531</td>\n",
       "      <td>18172.039062</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>17562.230469</td>\n",
       "      <td>17975.310547</td>\n",
       "      <td>17509.640625</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>26299.539062</td>\n",
       "      <td>26438.650391</td>\n",
       "      <td>26294.849609</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>26570.779297</td>\n",
       "      <td>26620.490234</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>26309.339844</td>\n",
       "      <td>26354.269531</td>\n",
       "      <td>26199.669922</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>26074.900391</td>\n",
       "      <td>26126.699219</td>\n",
       "      <td>25953.919922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>26288.000000</td>\n",
       "      <td>26321.369141</td>\n",
       "      <td>26067.919922</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  UP\n",
       "Date                                                                  \n",
       "2016-01-04  18818.580078  18951.119141  18394.429688  18450.980469   0\n",
       "2016-01-05  18398.759766  18547.380859  18327.519531  18374.000000   0\n",
       "2016-01-06  18410.570312  18469.380859  18064.300781  18191.320312   0\n",
       "2016-01-07  18139.769531  18172.039062  17767.339844  17767.339844   1\n",
       "2016-01-08  17562.230469  17975.310547  17509.640625  17697.960938   0\n",
       "...                  ...           ...           ...           ...  ..\n",
       "2022-12-26  26299.539062  26438.650391  26294.849609  26405.869141   0\n",
       "2022-12-27  26570.779297  26620.490234  26447.869141  26447.869141   1\n",
       "2022-12-28  26309.339844  26354.269531  26199.669922  26340.500000   1\n",
       "2022-12-29  26074.900391  26126.699219  25953.919922  26093.669922   0\n",
       "2022-12-30  26288.000000  26321.369141  26067.919922  26094.500000   0\n",
       "\n",
       "[1710 rows x 5 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(keys='Date', inplace=True)\n",
    "df\n",
    "\n",
    "df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a1709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df8808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61b4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35767a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c76c4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>18818.580078</td>\n",
       "      <td>18951.119141</td>\n",
       "      <td>18394.429688</td>\n",
       "      <td>18450.980469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>18398.759766</td>\n",
       "      <td>18547.380859</td>\n",
       "      <td>18327.519531</td>\n",
       "      <td>18374.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>18410.570312</td>\n",
       "      <td>18469.380859</td>\n",
       "      <td>18064.300781</td>\n",
       "      <td>18191.320312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>18139.769531</td>\n",
       "      <td>18172.039062</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>17767.339844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>17562.230469</td>\n",
       "      <td>17975.310547</td>\n",
       "      <td>17509.640625</td>\n",
       "      <td>17697.960938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-24</th>\n",
       "      <td>28836.050781</td>\n",
       "      <td>28870.130859</td>\n",
       "      <td>28773.500000</td>\n",
       "      <td>28782.589844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>28786.330078</td>\n",
       "      <td>28805.279297</td>\n",
       "      <td>28658.820312</td>\n",
       "      <td>28676.460938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>28953.320312</td>\n",
       "      <td>29121.009766</td>\n",
       "      <td>28879.679688</td>\n",
       "      <td>29069.160156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>28995.730469</td>\n",
       "      <td>29106.279297</td>\n",
       "      <td>28729.609375</td>\n",
       "      <td>28906.880859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>28794.240234</td>\n",
       "      <td>28904.419922</td>\n",
       "      <td>28579.490234</td>\n",
       "      <td>28791.710938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  UP\n",
       "Date                                                                  \n",
       "2016-01-04  18818.580078  18951.119141  18394.429688  18450.980469   0\n",
       "2016-01-05  18398.759766  18547.380859  18327.519531  18374.000000   0\n",
       "2016-01-06  18410.570312  18469.380859  18064.300781  18191.320312   0\n",
       "2016-01-07  18139.769531  18172.039062  17767.339844  17767.339844   1\n",
       "2016-01-08  17562.230469  17975.310547  17509.640625  17697.960938   0\n",
       "...                  ...           ...           ...           ...  ..\n",
       "2021-12-24  28836.050781  28870.130859  28773.500000  28782.589844   0\n",
       "2021-12-27  28786.330078  28805.279297  28658.820312  28676.460938   1\n",
       "2021-12-28  28953.320312  29121.009766  28879.679688  29069.160156   0\n",
       "2021-12-29  28995.730469  29106.279297  28729.609375  28906.880859   0\n",
       "2021-12-30  28794.240234  28904.419922  28579.490234  28791.710938   1\n",
       "\n",
       "[1466 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[ : '2022-01-01']\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "202c71c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>29098.410156</td>\n",
       "      <td>29323.789062</td>\n",
       "      <td>28954.560547</td>\n",
       "      <td>29301.789062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>29288.800781</td>\n",
       "      <td>29388.160156</td>\n",
       "      <td>29204.449219</td>\n",
       "      <td>29332.160156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>29136.750000</td>\n",
       "      <td>29158.949219</td>\n",
       "      <td>28487.869141</td>\n",
       "      <td>28487.869141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>28711.529297</td>\n",
       "      <td>28813.089844</td>\n",
       "      <td>28293.699219</td>\n",
       "      <td>28478.560547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>28380.900391</td>\n",
       "      <td>28473.470703</td>\n",
       "      <td>28089.490234</td>\n",
       "      <td>28222.480469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>26299.539062</td>\n",
       "      <td>26438.650391</td>\n",
       "      <td>26294.849609</td>\n",
       "      <td>26405.869141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>26570.779297</td>\n",
       "      <td>26620.490234</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>26447.869141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>26309.339844</td>\n",
       "      <td>26354.269531</td>\n",
       "      <td>26199.669922</td>\n",
       "      <td>26340.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>26074.900391</td>\n",
       "      <td>26126.699219</td>\n",
       "      <td>25953.919922</td>\n",
       "      <td>26093.669922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>26288.000000</td>\n",
       "      <td>26321.369141</td>\n",
       "      <td>26067.919922</td>\n",
       "      <td>26094.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  UP\n",
       "Date                                                                  \n",
       "2022-01-04  29098.410156  29323.789062  28954.560547  29301.789062   1\n",
       "2022-01-05  29288.800781  29388.160156  29204.449219  29332.160156   0\n",
       "2022-01-06  29136.750000  29158.949219  28487.869141  28487.869141   0\n",
       "2022-01-07  28711.529297  28813.089844  28293.699219  28478.560547   0\n",
       "2022-01-11  28380.900391  28473.470703  28089.490234  28222.480469   1\n",
       "...                  ...           ...           ...           ...  ..\n",
       "2022-12-26  26299.539062  26438.650391  26294.849609  26405.869141   0\n",
       "2022-12-27  26570.779297  26620.490234  26447.869141  26447.869141   1\n",
       "2022-12-28  26309.339844  26354.269531  26199.669922  26340.500000   1\n",
       "2022-12-29  26074.900391  26126.699219  25953.919922  26093.669922   0\n",
       "2022-12-30  26288.000000  26321.369141  26067.919922  26094.500000   0\n",
       "\n",
       "[244 rows x 5 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df['2022-01-01' : ]\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "14c5a7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Open          High           Low         Close\n",
      "Date                                                              \n",
      "2016-01-04  18818.580078  18951.119141  18394.429688  18450.980469\n",
      "2016-01-05  18398.759766  18547.380859  18327.519531  18374.000000\n",
      "2016-01-06  18410.570312  18469.380859  18064.300781  18191.320312\n",
      "2016-01-07  18139.769531  18172.039062  17767.339844  17767.339844\n",
      "2016-01-08  17562.230469  17975.310547  17509.640625  17697.960938\n",
      "...                  ...           ...           ...           ...\n",
      "2021-12-24  28836.050781  28870.130859  28773.500000  28782.589844\n",
      "2021-12-27  28786.330078  28805.279297  28658.820312  28676.460938\n",
      "2021-12-28  28953.320312  29121.009766  28879.679688  29069.160156\n",
      "2021-12-29  28995.730469  29106.279297  28729.609375  28906.880859\n",
      "2021-12-30  28794.240234  28904.419922  28579.490234  28791.710938\n",
      "\n",
      "[1466 rows x 4 columns]\n",
      "Date\n",
      "2016-01-04    0\n",
      "2016-01-05    0\n",
      "2016-01-06    0\n",
      "2016-01-07    1\n",
      "2016-01-08    0\n",
      "             ..\n",
      "2021-12-24    0\n",
      "2021-12-27    1\n",
      "2021-12-28    0\n",
      "2021-12-29    0\n",
      "2021-12-30    1\n",
      "Name: UP, Length: 1466, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[['Open', 'High', 'Low', 'Close']]\n",
    "y_train = df_train['UP']\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "67951ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Open          High           Low         Close\n",
      "Date                                                              \n",
      "2022-01-04  29098.410156  29323.789062  28954.560547  29301.789062\n",
      "2022-01-05  29288.800781  29388.160156  29204.449219  29332.160156\n",
      "2022-01-06  29136.750000  29158.949219  28487.869141  28487.869141\n",
      "2022-01-07  28711.529297  28813.089844  28293.699219  28478.560547\n",
      "2022-01-11  28380.900391  28473.470703  28089.490234  28222.480469\n",
      "...                  ...           ...           ...           ...\n",
      "2022-12-26  26299.539062  26438.650391  26294.849609  26405.869141\n",
      "2022-12-27  26570.779297  26620.490234  26447.869141  26447.869141\n",
      "2022-12-28  26309.339844  26354.269531  26199.669922  26340.500000\n",
      "2022-12-29  26074.900391  26126.699219  25953.919922  26093.669922\n",
      "2022-12-30  26288.000000  26321.369141  26067.919922  26094.500000\n",
      "\n",
      "[244 rows x 4 columns]\n",
      "Date\n",
      "2022-01-04    1\n",
      "2022-01-05    0\n",
      "2022-01-06    0\n",
      "2022-01-07    0\n",
      "2022-01-11    1\n",
      "             ..\n",
      "2022-12-26    0\n",
      "2022-12-27    1\n",
      "2022-12-28    1\n",
      "2022-12-29    0\n",
      "2022-12-30    0\n",
      "Name: UP, Length: 244, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_val = df_val[['Open', 'High', 'Low', 'Close']]\n",
    "y_val = df_val['UP']\n",
    "\n",
    "print(X_val)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d36a84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def std_to_np(df):\n",
    "    df_list = []\n",
    "    df = np.array(df)\n",
    "    for i in range(0, len(df) - 3, 4):\n",
    "        df_s = df[i:i+4]\n",
    "        scl = StandardScaler()\n",
    "        df_std = scl.fit_transform(df_s)\n",
    "        df_list.append(df_std)\n",
    "    return np.array(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4e6fd3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366, 4, 4)\n",
      "(61, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train_np_array = std_to_np(X_train)\n",
    "X_val_np_array = std_to_np(X_val)\n",
    "\n",
    "print(X_train_np_array.shape)\n",
    "print(X_val_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4b628ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2016-01-04    0\n",
      "2016-01-05    0\n",
      "2016-01-06    0\n",
      "2016-01-07    1\n",
      "2016-01-08    0\n",
      "             ..\n",
      "2021-12-24    0\n",
      "2021-12-27    1\n",
      "2021-12-28    0\n",
      "2021-12-29    0\n",
      "2021-12-30    1\n",
      "Name: UP, Length: 1466, dtype: int64\n",
      "Date\n",
      "2022-01-04    1\n",
      "2022-01-05    0\n",
      "2022-01-06    0\n",
      "2022-01-07    0\n",
      "2022-01-11    1\n",
      "             ..\n",
      "2022-12-26    0\n",
      "2022-12-27    1\n",
      "2022-12-28    1\n",
      "2022-12-29    0\n",
      "2022-12-30    0\n",
      "Name: UP, Length: 244, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef15b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_val = pd.get_dummies(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8bbe33b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "y_train_new = y_train[3::4]\n",
    "y_val_new = y_val[3::4]\n",
    "\n",
    "print(len(y_train_new))\n",
    "print(len(y_val_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9dd8bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "883d501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 33ms/step - loss: 0.6924 - accuracy: 0.5137 - val_loss: 0.6853 - val_accuracy: 0.5676\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.5445 - val_loss: 0.6819 - val_accuracy: 0.5676\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6876 - accuracy: 0.5445 - val_loss: 0.6825 - val_accuracy: 0.5676\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6874 - accuracy: 0.5445 - val_loss: 0.6832 - val_accuracy: 0.5676\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6881 - accuracy: 0.5411 - val_loss: 0.6812 - val_accuracy: 0.5676\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6868 - accuracy: 0.5616 - val_loss: 0.6810 - val_accuracy: 0.5541\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6878 - accuracy: 0.5651 - val_loss: 0.6784 - val_accuracy: 0.5676\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6877 - accuracy: 0.5616 - val_loss: 0.6788 - val_accuracy: 0.5946\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6866 - accuracy: 0.5342 - val_loss: 0.6753 - val_accuracy: 0.5676\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6843 - accuracy: 0.5582 - val_loss: 0.6739 - val_accuracy: 0.5811\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6847 - accuracy: 0.5685 - val_loss: 0.6730 - val_accuracy: 0.5946\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6850 - accuracy: 0.5788 - val_loss: 0.6687 - val_accuracy: 0.5811\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6800 - accuracy: 0.5822 - val_loss: 0.6698 - val_accuracy: 0.5811\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6778 - accuracy: 0.5788 - val_loss: 0.6611 - val_accuracy: 0.6081\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6757 - accuracy: 0.5753 - val_loss: 0.6577 - val_accuracy: 0.6081\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6755 - accuracy: 0.5822 - val_loss: 0.6534 - val_accuracy: 0.6081\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6810 - accuracy: 0.5890 - val_loss: 0.6573 - val_accuracy: 0.6081\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6663 - accuracy: 0.5822 - val_loss: 0.6588 - val_accuracy: 0.6081\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6684 - accuracy: 0.5651 - val_loss: 0.6452 - val_accuracy: 0.6081\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6685 - accuracy: 0.5822 - val_loss: 0.6532 - val_accuracy: 0.6081\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6624 - accuracy: 0.5925 - val_loss: 0.6511 - val_accuracy: 0.6216\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6548 - accuracy: 0.6062 - val_loss: 0.6491 - val_accuracy: 0.6081\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6529 - accuracy: 0.6027 - val_loss: 0.6439 - val_accuracy: 0.5946\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6523 - accuracy: 0.6062 - val_loss: 0.6339 - val_accuracy: 0.6081\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6366 - accuracy: 0.6062 - val_loss: 0.6337 - val_accuracy: 0.6081\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6311 - accuracy: 0.6336 - val_loss: 0.6270 - val_accuracy: 0.5946\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.6225 - accuracy: 0.6301 - val_loss: 0.6248 - val_accuracy: 0.6081\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6113 - accuracy: 0.6404 - val_loss: 0.6355 - val_accuracy: 0.5811\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6105 - accuracy: 0.6336 - val_loss: 0.6194 - val_accuracy: 0.6081\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6054 - accuracy: 0.6473 - val_loss: 0.6252 - val_accuracy: 0.6216\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5972 - accuracy: 0.6507 - val_loss: 0.6441 - val_accuracy: 0.6216\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5908 - accuracy: 0.6678 - val_loss: 0.6350 - val_accuracy: 0.6081\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5947 - accuracy: 0.6473 - val_loss: 0.6118 - val_accuracy: 0.6216\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6132 - accuracy: 0.6199 - val_loss: 0.6517 - val_accuracy: 0.5811\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5971 - accuracy: 0.6404 - val_loss: 0.6402 - val_accuracy: 0.6351\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5828 - accuracy: 0.6678 - val_loss: 0.6325 - val_accuracy: 0.6216\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5651 - accuracy: 0.6575 - val_loss: 0.6812 - val_accuracy: 0.6216\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.5673 - accuracy: 0.6438 - val_loss: 0.6603 - val_accuracy: 0.5676\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6205 - accuracy: 0.6507 - val_loss: 0.6782 - val_accuracy: 0.5811\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6354 - accuracy: 0.6062 - val_loss: 0.6149 - val_accuracy: 0.5946\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.6338 - accuracy: 0.6096 - val_loss: 0.6332 - val_accuracy: 0.6216\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6214 - accuracy: 0.6062 - val_loss: 0.6230 - val_accuracy: 0.5946\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5980 - accuracy: 0.6610 - val_loss: 0.6228 - val_accuracy: 0.6216\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5903 - accuracy: 0.6541 - val_loss: 0.6303 - val_accuracy: 0.6081\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5699 - accuracy: 0.6610 - val_loss: 0.6376 - val_accuracy: 0.6081\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5568 - accuracy: 0.6918 - val_loss: 0.6368 - val_accuracy: 0.6486\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5523 - accuracy: 0.7192 - val_loss: 0.6513 - val_accuracy: 0.6216\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5439 - accuracy: 0.6849 - val_loss: 0.6782 - val_accuracy: 0.6081\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5361 - accuracy: 0.6986 - val_loss: 0.6961 - val_accuracy: 0.5946\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5340 - accuracy: 0.6918 - val_loss: 0.6978 - val_accuracy: 0.6216\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5162 - accuracy: 0.6918 - val_loss: 0.7089 - val_accuracy: 0.6081\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5038 - accuracy: 0.7226 - val_loss: 0.7315 - val_accuracy: 0.5811\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5040 - accuracy: 0.7089 - val_loss: 0.7486 - val_accuracy: 0.5811\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.4995 - accuracy: 0.7192 - val_loss: 0.7264 - val_accuracy: 0.5676\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4942 - accuracy: 0.7123 - val_loss: 0.8055 - val_accuracy: 0.5541\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4780 - accuracy: 0.7329 - val_loss: 0.7910 - val_accuracy: 0.5541\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4558 - accuracy: 0.7637 - val_loss: 0.7946 - val_accuracy: 0.6216\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4749 - accuracy: 0.7363 - val_loss: 0.9868 - val_accuracy: 0.5405\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5089 - accuracy: 0.7329 - val_loss: 0.7540 - val_accuracy: 0.6351\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4719 - accuracy: 0.7363 - val_loss: 0.8040 - val_accuracy: 0.5811\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4480 - accuracy: 0.7671 - val_loss: 0.8849 - val_accuracy: 0.5676\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4415 - accuracy: 0.7911 - val_loss: 1.0385 - val_accuracy: 0.5541\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4457 - accuracy: 0.7466 - val_loss: 0.8405 - val_accuracy: 0.6081\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4228 - accuracy: 0.7637 - val_loss: 0.8768 - val_accuracy: 0.6486\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4180 - accuracy: 0.7774 - val_loss: 0.9876 - val_accuracy: 0.5946\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3985 - accuracy: 0.7705 - val_loss: 0.9823 - val_accuracy: 0.5811\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.4131 - accuracy: 0.7877 - val_loss: 1.3454 - val_accuracy: 0.4459\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4767 - accuracy: 0.7466 - val_loss: 0.8129 - val_accuracy: 0.5946\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6163 - accuracy: 0.6849 - val_loss: 1.0059 - val_accuracy: 0.5405\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5204 - accuracy: 0.6918 - val_loss: 0.8269 - val_accuracy: 0.5405\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4789 - accuracy: 0.7500 - val_loss: 0.9010 - val_accuracy: 0.5405\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4524 - accuracy: 0.7808 - val_loss: 0.8003 - val_accuracy: 0.5541\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4282 - accuracy: 0.7705 - val_loss: 0.9292 - val_accuracy: 0.5676\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.4199 - accuracy: 0.7603 - val_loss: 0.9030 - val_accuracy: 0.5811\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3965 - accuracy: 0.8048 - val_loss: 0.9632 - val_accuracy: 0.5676\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3775 - accuracy: 0.7945 - val_loss: 0.9933 - val_accuracy: 0.5676\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3646 - accuracy: 0.8185 - val_loss: 0.9539 - val_accuracy: 0.5946\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3785 - accuracy: 0.8014 - val_loss: 1.0850 - val_accuracy: 0.4730\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4271 - accuracy: 0.7705 - val_loss: 0.8988 - val_accuracy: 0.5811\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3690 - accuracy: 0.8185 - val_loss: 0.9975 - val_accuracy: 0.5135\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3654 - accuracy: 0.8014 - val_loss: 0.9539 - val_accuracy: 0.6081\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3272 - accuracy: 0.8562 - val_loss: 1.0938 - val_accuracy: 0.5541\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3241 - accuracy: 0.8425 - val_loss: 1.0757 - val_accuracy: 0.5541\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.3267 - accuracy: 0.8459 - val_loss: 1.0774 - val_accuracy: 0.5270\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3548 - accuracy: 0.8288 - val_loss: 1.1285 - val_accuracy: 0.5946\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3810 - accuracy: 0.7911 - val_loss: 1.1874 - val_accuracy: 0.5676\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3571 - accuracy: 0.8253 - val_loss: 1.0473 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3321 - accuracy: 0.8151 - val_loss: 1.0394 - val_accuracy: 0.5541\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.2915 - accuracy: 0.8733 - val_loss: 1.0387 - val_accuracy: 0.5811\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3941 - accuracy: 0.8082 - val_loss: 1.0619 - val_accuracy: 0.4459\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3636 - accuracy: 0.7911 - val_loss: 0.9192 - val_accuracy: 0.5405\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3643 - accuracy: 0.8116 - val_loss: 0.9777 - val_accuracy: 0.5135\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3492 - accuracy: 0.8322 - val_loss: 1.0302 - val_accuracy: 0.5811\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3550 - accuracy: 0.8219 - val_loss: 1.0572 - val_accuracy: 0.5135\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3152 - accuracy: 0.8527 - val_loss: 1.2478 - val_accuracy: 0.5270\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3373 - accuracy: 0.8322 - val_loss: 1.0733 - val_accuracy: 0.5676\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3334 - accuracy: 0.8459 - val_loss: 0.9611 - val_accuracy: 0.5541\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.3071 - accuracy: 0.8459 - val_loss: 1.0181 - val_accuracy: 0.5676\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2855 - accuracy: 0.8733 - val_loss: 1.2219 - val_accuracy: 0.5541\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.2793 - accuracy: 0.8596 - val_loss: 1.2809 - val_accuracy: 0.5676\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.1781 - accuracy: 0.5410\n",
      "Test accuracy: 54.1%\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, activation='relu', batch_input_shape=(None, X_train_np_array.shape[1], X_train_np_array.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "'''model.compile(\n",
    "              loss=\"categorical_crossentropy\", \n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy']\n",
    "             )'''\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs=10)\n",
    "history = model.fit(X_train_np_array, y_train_new, epochs=100, validation_split=0.2,)\n",
    "\n",
    "_, accuracy = model.evaluate(X_val_np_array, y_val_new)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "x = model.predict(X_train_np_array)\n",
    "a = model.predict(X_val_np_array)\n",
    "\n",
    "x = np.where(x < 0.5, 0, 1)\n",
    "a = np.where(a < 0.5, 0, 1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fbca1d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e2e21acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 3s 67ms/step - loss: 0.6948 - accuracy: 0.4966 - val_loss: 0.6878 - val_accuracy: 0.5676\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6901 - accuracy: 0.5445 - val_loss: 0.6855 - val_accuracy: 0.5676\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6895 - accuracy: 0.5479 - val_loss: 0.6845 - val_accuracy: 0.5676\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6896 - accuracy: 0.5445 - val_loss: 0.6841 - val_accuracy: 0.5676\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6877 - accuracy: 0.5445 - val_loss: 0.6836 - val_accuracy: 0.5676\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6877 - accuracy: 0.5445 - val_loss: 0.6826 - val_accuracy: 0.5676\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6854 - accuracy: 0.5479 - val_loss: 0.6820 - val_accuracy: 0.5676\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6869 - accuracy: 0.5411 - val_loss: 0.6805 - val_accuracy: 0.5676\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6841 - accuracy: 0.5479 - val_loss: 0.6774 - val_accuracy: 0.5676\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6872 - accuracy: 0.5445 - val_loss: 0.6759 - val_accuracy: 0.5676\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6854 - accuracy: 0.5479 - val_loss: 0.6765 - val_accuracy: 0.5676\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6833 - accuracy: 0.5582 - val_loss: 0.6743 - val_accuracy: 0.5676\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6899 - accuracy: 0.5514 - val_loss: 0.6741 - val_accuracy: 0.5811\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6853 - accuracy: 0.5616 - val_loss: 0.6709 - val_accuracy: 0.5676\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6838 - accuracy: 0.5651 - val_loss: 0.6723 - val_accuracy: 0.5811\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6818 - accuracy: 0.5788 - val_loss: 0.6729 - val_accuracy: 0.6081\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6840 - accuracy: 0.5582 - val_loss: 0.6670 - val_accuracy: 0.6081\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6761 - accuracy: 0.5822 - val_loss: 0.6635 - val_accuracy: 0.6081\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6838 - accuracy: 0.5582 - val_loss: 0.6625 - val_accuracy: 0.6081\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6798 - accuracy: 0.5925 - val_loss: 0.6563 - val_accuracy: 0.6081\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6820 - accuracy: 0.5685 - val_loss: 0.6530 - val_accuracy: 0.6216\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6780 - accuracy: 0.5856 - val_loss: 0.6444 - val_accuracy: 0.5946\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6653 - accuracy: 0.6096 - val_loss: 0.6380 - val_accuracy: 0.6216\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6657 - accuracy: 0.6199 - val_loss: 0.6330 - val_accuracy: 0.5946\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6566 - accuracy: 0.6199 - val_loss: 0.6376 - val_accuracy: 0.5946\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6527 - accuracy: 0.6027 - val_loss: 0.6372 - val_accuracy: 0.6351\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6477 - accuracy: 0.6370 - val_loss: 0.6269 - val_accuracy: 0.5811\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6582 - accuracy: 0.6336 - val_loss: 0.6285 - val_accuracy: 0.6351\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6436 - accuracy: 0.6438 - val_loss: 0.6224 - val_accuracy: 0.6216\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6443 - accuracy: 0.6130 - val_loss: 0.6118 - val_accuracy: 0.5946\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6430 - accuracy: 0.6096 - val_loss: 0.6300 - val_accuracy: 0.6622\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6291 - accuracy: 0.6473 - val_loss: 0.6174 - val_accuracy: 0.6081\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6336 - accuracy: 0.6164 - val_loss: 0.6140 - val_accuracy: 0.5946\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6354 - accuracy: 0.6199 - val_loss: 0.6251 - val_accuracy: 0.6216\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6193 - accuracy: 0.6336 - val_loss: 0.6198 - val_accuracy: 0.6081\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6256 - accuracy: 0.6164 - val_loss: 0.6267 - val_accuracy: 0.6351\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6247 - accuracy: 0.6438 - val_loss: 0.6287 - val_accuracy: 0.6351\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6288 - accuracy: 0.6438 - val_loss: 0.6353 - val_accuracy: 0.6081\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6148 - accuracy: 0.6610 - val_loss: 0.6173 - val_accuracy: 0.6081\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6222 - accuracy: 0.6233 - val_loss: 0.6226 - val_accuracy: 0.5946\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6031 - accuracy: 0.6575 - val_loss: 0.6388 - val_accuracy: 0.6486\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6018 - accuracy: 0.6712 - val_loss: 0.6320 - val_accuracy: 0.5946\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6078 - accuracy: 0.6404 - val_loss: 0.6323 - val_accuracy: 0.6216\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5964 - accuracy: 0.6541 - val_loss: 0.6286 - val_accuracy: 0.6486\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5958 - accuracy: 0.6541 - val_loss: 0.6286 - val_accuracy: 0.6216\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5871 - accuracy: 0.6507 - val_loss: 0.6374 - val_accuracy: 0.6351\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5893 - accuracy: 0.6644 - val_loss: 0.6301 - val_accuracy: 0.6216\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5856 - accuracy: 0.6575 - val_loss: 0.6365 - val_accuracy: 0.6622\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5795 - accuracy: 0.6610 - val_loss: 0.6350 - val_accuracy: 0.6486\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5624 - accuracy: 0.6575 - val_loss: 0.6383 - val_accuracy: 0.6351\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5591 - accuracy: 0.7055 - val_loss: 0.6445 - val_accuracy: 0.6351\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6080 - accuracy: 0.6199 - val_loss: 0.6509 - val_accuracy: 0.5946\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5887 - accuracy: 0.6473 - val_loss: 0.6395 - val_accuracy: 0.6351\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5965 - accuracy: 0.6644 - val_loss: 0.6112 - val_accuracy: 0.6486\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5835 - accuracy: 0.6986 - val_loss: 0.6341 - val_accuracy: 0.6216\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5713 - accuracy: 0.6575 - val_loss: 0.6104 - val_accuracy: 0.6216\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5689 - accuracy: 0.6781 - val_loss: 0.6355 - val_accuracy: 0.6081\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5624 - accuracy: 0.6473 - val_loss: 0.6531 - val_accuracy: 0.5946\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5612 - accuracy: 0.6781 - val_loss: 0.6523 - val_accuracy: 0.5811\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5531 - accuracy: 0.6644 - val_loss: 0.6322 - val_accuracy: 0.5676\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5577 - accuracy: 0.6610 - val_loss: 0.6501 - val_accuracy: 0.6216\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5292 - accuracy: 0.7123 - val_loss: 0.6671 - val_accuracy: 0.5811\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5383 - accuracy: 0.6884 - val_loss: 0.6736 - val_accuracy: 0.5676\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5371 - accuracy: 0.7021 - val_loss: 0.6471 - val_accuracy: 0.6081\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5268 - accuracy: 0.7089 - val_loss: 0.6667 - val_accuracy: 0.5811\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5256 - accuracy: 0.6952 - val_loss: 0.6725 - val_accuracy: 0.6216\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5172 - accuracy: 0.6986 - val_loss: 0.6566 - val_accuracy: 0.5811\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5363 - accuracy: 0.7123 - val_loss: 0.7231 - val_accuracy: 0.6216\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5185 - accuracy: 0.7055 - val_loss: 0.7401 - val_accuracy: 0.6081\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5167 - accuracy: 0.6986 - val_loss: 0.7117 - val_accuracy: 0.5676\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5147 - accuracy: 0.6952 - val_loss: 0.7015 - val_accuracy: 0.5946\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4888 - accuracy: 0.7363 - val_loss: 0.6811 - val_accuracy: 0.5946\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5719 - accuracy: 0.6678 - val_loss: 0.7725 - val_accuracy: 0.6216\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5358 - accuracy: 0.7295 - val_loss: 0.6999 - val_accuracy: 0.5946\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5367 - accuracy: 0.6952 - val_loss: 0.6593 - val_accuracy: 0.5946\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4993 - accuracy: 0.7158 - val_loss: 0.6492 - val_accuracy: 0.6081\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4979 - accuracy: 0.7192 - val_loss: 0.6814 - val_accuracy: 0.5946\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4829 - accuracy: 0.7568 - val_loss: 0.7139 - val_accuracy: 0.6216\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4715 - accuracy: 0.7637 - val_loss: 0.7295 - val_accuracy: 0.5946\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4734 - accuracy: 0.7500 - val_loss: 0.7234 - val_accuracy: 0.5811\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4665 - accuracy: 0.7432 - val_loss: 0.7210 - val_accuracy: 0.6351\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4611 - accuracy: 0.7432 - val_loss: 0.7386 - val_accuracy: 0.5405\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5444 - accuracy: 0.7260 - val_loss: 0.8086 - val_accuracy: 0.5405\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5234 - accuracy: 0.7055 - val_loss: 0.6701 - val_accuracy: 0.6081\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5090 - accuracy: 0.7123 - val_loss: 0.7138 - val_accuracy: 0.6081\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4636 - accuracy: 0.7432 - val_loss: 0.7787 - val_accuracy: 0.5541\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4635 - accuracy: 0.7432 - val_loss: 0.7973 - val_accuracy: 0.5946\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4577 - accuracy: 0.7500 - val_loss: 0.7744 - val_accuracy: 0.6081\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4282 - accuracy: 0.7877 - val_loss: 0.8449 - val_accuracy: 0.5676\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4210 - accuracy: 0.7705 - val_loss: 0.7937 - val_accuracy: 0.6081\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4405 - accuracy: 0.7603 - val_loss: 0.8201 - val_accuracy: 0.6351\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4198 - accuracy: 0.7945 - val_loss: 0.8351 - val_accuracy: 0.5946\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4102 - accuracy: 0.8116 - val_loss: 0.9356 - val_accuracy: 0.6216\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4094 - accuracy: 0.7945 - val_loss: 0.8846 - val_accuracy: 0.6081\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4188 - accuracy: 0.7568 - val_loss: 0.7696 - val_accuracy: 0.6081\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4325 - accuracy: 0.7911 - val_loss: 1.0139 - val_accuracy: 0.5676\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4725 - accuracy: 0.7397 - val_loss: 0.7324 - val_accuracy: 0.6081\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4754 - accuracy: 0.7397 - val_loss: 0.7558 - val_accuracy: 0.5676\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4323 - accuracy: 0.7705 - val_loss: 0.7494 - val_accuracy: 0.5811\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4299 - accuracy: 0.7603 - val_loss: 0.7591 - val_accuracy: 0.5946\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "fold 0 accracy: 0.5737704918032787\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 3s 70ms/step - loss: 0.6957 - accuracy: 0.4897 - val_loss: 0.6861 - val_accuracy: 0.5676\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6913 - accuracy: 0.5445 - val_loss: 0.6848 - val_accuracy: 0.5676\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6871 - accuracy: 0.5445 - val_loss: 0.6835 - val_accuracy: 0.5676\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6889 - accuracy: 0.5445 - val_loss: 0.6812 - val_accuracy: 0.5676\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6884 - accuracy: 0.5445 - val_loss: 0.6796 - val_accuracy: 0.5676\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6871 - accuracy: 0.5445 - val_loss: 0.6778 - val_accuracy: 0.5676\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6864 - accuracy: 0.5445 - val_loss: 0.6787 - val_accuracy: 0.5676\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6868 - accuracy: 0.5514 - val_loss: 0.6781 - val_accuracy: 0.5676\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6860 - accuracy: 0.5445 - val_loss: 0.6769 - val_accuracy: 0.5676\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6865 - accuracy: 0.5479 - val_loss: 0.6776 - val_accuracy: 0.5676\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6841 - accuracy: 0.5548 - val_loss: 0.6757 - val_accuracy: 0.5676\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6850 - accuracy: 0.5582 - val_loss: 0.6722 - val_accuracy: 0.5676\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6879 - accuracy: 0.5582 - val_loss: 0.6703 - val_accuracy: 0.5676\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6887 - accuracy: 0.5445 - val_loss: 0.6696 - val_accuracy: 0.5676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6811 - accuracy: 0.5753 - val_loss: 0.6699 - val_accuracy: 0.5811\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6835 - accuracy: 0.5890 - val_loss: 0.6694 - val_accuracy: 0.5946\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6784 - accuracy: 0.5753 - val_loss: 0.6661 - val_accuracy: 0.5946\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6860 - accuracy: 0.5445 - val_loss: 0.6627 - val_accuracy: 0.6216\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6827 - accuracy: 0.5342 - val_loss: 0.6646 - val_accuracy: 0.5811\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6767 - accuracy: 0.5719 - val_loss: 0.6612 - val_accuracy: 0.6081\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6735 - accuracy: 0.5925 - val_loss: 0.6556 - val_accuracy: 0.5946\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6725 - accuracy: 0.5925 - val_loss: 0.6476 - val_accuracy: 0.5946\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6659 - accuracy: 0.6027 - val_loss: 0.6413 - val_accuracy: 0.5946\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6681 - accuracy: 0.5993 - val_loss: 0.6318 - val_accuracy: 0.5811\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6577 - accuracy: 0.6130 - val_loss: 0.6346 - val_accuracy: 0.5946\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6598 - accuracy: 0.5993 - val_loss: 0.6372 - val_accuracy: 0.5946\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6530 - accuracy: 0.6130 - val_loss: 0.6327 - val_accuracy: 0.5946\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6489 - accuracy: 0.6267 - val_loss: 0.6398 - val_accuracy: 0.6081\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6542 - accuracy: 0.6096 - val_loss: 0.6243 - val_accuracy: 0.5946\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6415 - accuracy: 0.6301 - val_loss: 0.6219 - val_accuracy: 0.5946\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6378 - accuracy: 0.6130 - val_loss: 0.6188 - val_accuracy: 0.5946\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6339 - accuracy: 0.6404 - val_loss: 0.6194 - val_accuracy: 0.5946\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6373 - accuracy: 0.6199 - val_loss: 0.6149 - val_accuracy: 0.6081\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6387 - accuracy: 0.5993 - val_loss: 0.6170 - val_accuracy: 0.5946\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6260 - accuracy: 0.6404 - val_loss: 0.6250 - val_accuracy: 0.5946\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6332 - accuracy: 0.6267 - val_loss: 0.6164 - val_accuracy: 0.6216\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6239 - accuracy: 0.6233 - val_loss: 0.6263 - val_accuracy: 0.6351\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6277 - accuracy: 0.6301 - val_loss: 0.6263 - val_accuracy: 0.6351\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6190 - accuracy: 0.6301 - val_loss: 0.6181 - val_accuracy: 0.5946\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6134 - accuracy: 0.6267 - val_loss: 0.6282 - val_accuracy: 0.6216\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6153 - accuracy: 0.6130 - val_loss: 0.6269 - val_accuracy: 0.6216\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6149 - accuracy: 0.6267 - val_loss: 0.6221 - val_accuracy: 0.6351\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6217 - accuracy: 0.6062 - val_loss: 0.6165 - val_accuracy: 0.6351\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6164 - accuracy: 0.6199 - val_loss: 0.6448 - val_accuracy: 0.6216\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6091 - accuracy: 0.6438 - val_loss: 0.6218 - val_accuracy: 0.6351\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6234 - accuracy: 0.6164 - val_loss: 0.6189 - val_accuracy: 0.6486\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6043 - accuracy: 0.6199 - val_loss: 0.6365 - val_accuracy: 0.6081\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5939 - accuracy: 0.6541 - val_loss: 0.6114 - val_accuracy: 0.6351\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5919 - accuracy: 0.6678 - val_loss: 0.6176 - val_accuracy: 0.6351\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5850 - accuracy: 0.6473 - val_loss: 0.6177 - val_accuracy: 0.6486\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5838 - accuracy: 0.6370 - val_loss: 0.6207 - val_accuracy: 0.6351\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5706 - accuracy: 0.6918 - val_loss: 0.6297 - val_accuracy: 0.5811\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5797 - accuracy: 0.6884 - val_loss: 0.6136 - val_accuracy: 0.6351\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5802 - accuracy: 0.6986 - val_loss: 0.6357 - val_accuracy: 0.5676\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5745 - accuracy: 0.6747 - val_loss: 0.6177 - val_accuracy: 0.6081\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.5618 - accuracy: 0.6986 - val_loss: 0.6204 - val_accuracy: 0.6351\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5599 - accuracy: 0.6918 - val_loss: 0.6339 - val_accuracy: 0.6081\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.5627 - accuracy: 0.6678 - val_loss: 0.6570 - val_accuracy: 0.5676\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5593 - accuracy: 0.6644 - val_loss: 0.6223 - val_accuracy: 0.6081\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5602 - accuracy: 0.6815 - val_loss: 0.6319 - val_accuracy: 0.5541\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5509 - accuracy: 0.6918 - val_loss: 0.6135 - val_accuracy: 0.5676\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5644 - accuracy: 0.6712 - val_loss: 0.6309 - val_accuracy: 0.5946\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5469 - accuracy: 0.6849 - val_loss: 0.6289 - val_accuracy: 0.5811\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5558 - accuracy: 0.6918 - val_loss: 0.6683 - val_accuracy: 0.5405\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5632 - accuracy: 0.6918 - val_loss: 0.6369 - val_accuracy: 0.6081\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5669 - accuracy: 0.6438 - val_loss: 0.6369 - val_accuracy: 0.5676\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5378 - accuracy: 0.6986 - val_loss: 0.6417 - val_accuracy: 0.5405\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5346 - accuracy: 0.7055 - val_loss: 0.6368 - val_accuracy: 0.5541\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5176 - accuracy: 0.7021 - val_loss: 0.6561 - val_accuracy: 0.5946\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5144 - accuracy: 0.7021 - val_loss: 0.6637 - val_accuracy: 0.5946\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5302 - accuracy: 0.6849 - val_loss: 0.6396 - val_accuracy: 0.5676\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5122 - accuracy: 0.6952 - val_loss: 0.6720 - val_accuracy: 0.5405\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5186 - accuracy: 0.6952 - val_loss: 0.6778 - val_accuracy: 0.5541\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4940 - accuracy: 0.7226 - val_loss: 0.6988 - val_accuracy: 0.5405\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4919 - accuracy: 0.7260 - val_loss: 0.6787 - val_accuracy: 0.5811\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4922 - accuracy: 0.7329 - val_loss: 0.7156 - val_accuracy: 0.6081\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4838 - accuracy: 0.7568 - val_loss: 0.6972 - val_accuracy: 0.5676\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4973 - accuracy: 0.7089 - val_loss: 0.6908 - val_accuracy: 0.5676\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4940 - accuracy: 0.7329 - val_loss: 0.7245 - val_accuracy: 0.5676\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4800 - accuracy: 0.7295 - val_loss: 0.7147 - val_accuracy: 0.5811\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4858 - accuracy: 0.7192 - val_loss: 0.7237 - val_accuracy: 0.5405\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4899 - accuracy: 0.7295 - val_loss: 0.7158 - val_accuracy: 0.5405\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5171 - accuracy: 0.6884 - val_loss: 0.6391 - val_accuracy: 0.6757\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5005 - accuracy: 0.7260 - val_loss: 0.6880 - val_accuracy: 0.5541\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4626 - accuracy: 0.7432 - val_loss: 0.6872 - val_accuracy: 0.5405\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4605 - accuracy: 0.7534 - val_loss: 0.7056 - val_accuracy: 0.5676\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4510 - accuracy: 0.7603 - val_loss: 0.7342 - val_accuracy: 0.5541\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4282 - accuracy: 0.7534 - val_loss: 0.7443 - val_accuracy: 0.6081\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4442 - accuracy: 0.7466 - val_loss: 0.7598 - val_accuracy: 0.5946\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4299 - accuracy: 0.7568 - val_loss: 0.7654 - val_accuracy: 0.5811\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4404 - accuracy: 0.7432 - val_loss: 0.7360 - val_accuracy: 0.6216\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4392 - accuracy: 0.7568 - val_loss: 0.8223 - val_accuracy: 0.5541\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4231 - accuracy: 0.7705 - val_loss: 0.8343 - val_accuracy: 0.5270\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4637 - accuracy: 0.7466 - val_loss: 0.7759 - val_accuracy: 0.5676\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4688 - accuracy: 0.7192 - val_loss: 0.7475 - val_accuracy: 0.6081\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4474 - accuracy: 0.7603 - val_loss: 0.8216 - val_accuracy: 0.5946\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4479 - accuracy: 0.7432 - val_loss: 0.7673 - val_accuracy: 0.5946\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4166 - accuracy: 0.7842 - val_loss: 0.8194 - val_accuracy: 0.5541\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4250 - accuracy: 0.7774 - val_loss: 0.8161 - val_accuracy: 0.5676\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4622 - accuracy: 0.7397 - val_loss: 0.8149 - val_accuracy: 0.5541\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "fold 1 accracy: 0.47540983606557374\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 42ms/step - loss: 0.6942 - accuracy: 0.5068 - val_loss: 0.6854 - val_accuracy: 0.5676\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6896 - accuracy: 0.5514 - val_loss: 0.6835 - val_accuracy: 0.5676\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6896 - accuracy: 0.5445 - val_loss: 0.6828 - val_accuracy: 0.5676\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6903 - accuracy: 0.5445 - val_loss: 0.6802 - val_accuracy: 0.5676\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6884 - accuracy: 0.5445 - val_loss: 0.6780 - val_accuracy: 0.5676\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6876 - accuracy: 0.5445 - val_loss: 0.6780 - val_accuracy: 0.5676\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6906 - accuracy: 0.5445 - val_loss: 0.6778 - val_accuracy: 0.5676\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6840 - accuracy: 0.5445 - val_loss: 0.6780 - val_accuracy: 0.5676\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6850 - accuracy: 0.5445 - val_loss: 0.6770 - val_accuracy: 0.5676\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6868 - accuracy: 0.5445 - val_loss: 0.6756 - val_accuracy: 0.5676\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6875 - accuracy: 0.5445 - val_loss: 0.6737 - val_accuracy: 0.5676\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6837 - accuracy: 0.5445 - val_loss: 0.6733 - val_accuracy: 0.5676\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6887 - accuracy: 0.5445 - val_loss: 0.6724 - val_accuracy: 0.5676\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6841 - accuracy: 0.5479 - val_loss: 0.6697 - val_accuracy: 0.5676\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6859 - accuracy: 0.5479 - val_loss: 0.6696 - val_accuracy: 0.5676\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.5548 - val_loss: 0.6737 - val_accuracy: 0.6216\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6834 - accuracy: 0.5822 - val_loss: 0.6695 - val_accuracy: 0.6081\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6806 - accuracy: 0.5685 - val_loss: 0.6629 - val_accuracy: 0.6081\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6809 - accuracy: 0.5822 - val_loss: 0.6582 - val_accuracy: 0.6216\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6783 - accuracy: 0.5582 - val_loss: 0.6533 - val_accuracy: 0.6081\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6753 - accuracy: 0.5890 - val_loss: 0.6595 - val_accuracy: 0.6216\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6689 - accuracy: 0.5993 - val_loss: 0.6487 - val_accuracy: 0.6081\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6681 - accuracy: 0.5959 - val_loss: 0.6413 - val_accuracy: 0.6081\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6574 - accuracy: 0.5993 - val_loss: 0.6437 - val_accuracy: 0.6216\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6581 - accuracy: 0.6199 - val_loss: 0.6234 - val_accuracy: 0.6081\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6655 - accuracy: 0.5959 - val_loss: 0.6184 - val_accuracy: 0.6081\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6526 - accuracy: 0.5993 - val_loss: 0.6297 - val_accuracy: 0.6081\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6545 - accuracy: 0.6233 - val_loss: 0.6229 - val_accuracy: 0.5811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6447 - accuracy: 0.6062 - val_loss: 0.6207 - val_accuracy: 0.5946\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6388 - accuracy: 0.6301 - val_loss: 0.6206 - val_accuracy: 0.6081\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6338 - accuracy: 0.6301 - val_loss: 0.6111 - val_accuracy: 0.5811\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6388 - accuracy: 0.6164 - val_loss: 0.6223 - val_accuracy: 0.5946\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6339 - accuracy: 0.5753 - val_loss: 0.6138 - val_accuracy: 0.5946\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6274 - accuracy: 0.6096 - val_loss: 0.6154 - val_accuracy: 0.5946\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6245 - accuracy: 0.6438 - val_loss: 0.6144 - val_accuracy: 0.5811\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6283 - accuracy: 0.6199 - val_loss: 0.6084 - val_accuracy: 0.5946\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6126 - accuracy: 0.6473 - val_loss: 0.6231 - val_accuracy: 0.6081\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6179 - accuracy: 0.6473 - val_loss: 0.6183 - val_accuracy: 0.6216\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6107 - accuracy: 0.6404 - val_loss: 0.6123 - val_accuracy: 0.6081\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6071 - accuracy: 0.6747 - val_loss: 0.6197 - val_accuracy: 0.6351\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6008 - accuracy: 0.6747 - val_loss: 0.6242 - val_accuracy: 0.6351\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6008 - accuracy: 0.6336 - val_loss: 0.6265 - val_accuracy: 0.6216\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5876 - accuracy: 0.6918 - val_loss: 0.6213 - val_accuracy: 0.6216\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5899 - accuracy: 0.6404 - val_loss: 0.6243 - val_accuracy: 0.6216\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5955 - accuracy: 0.6678 - val_loss: 0.6170 - val_accuracy: 0.6216\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6127 - accuracy: 0.6336 - val_loss: 0.6123 - val_accuracy: 0.5946\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5872 - accuracy: 0.6541 - val_loss: 0.6385 - val_accuracy: 0.6486\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5774 - accuracy: 0.6575 - val_loss: 0.6314 - val_accuracy: 0.6351\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5789 - accuracy: 0.6712 - val_loss: 0.6390 - val_accuracy: 0.6486\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5876 - accuracy: 0.6644 - val_loss: 0.6248 - val_accuracy: 0.6757\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5636 - accuracy: 0.6644 - val_loss: 0.6333 - val_accuracy: 0.6351\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5781 - accuracy: 0.6541 - val_loss: 0.6615 - val_accuracy: 0.5946\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5399 - accuracy: 0.6849 - val_loss: 0.6371 - val_accuracy: 0.6757\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5507 - accuracy: 0.6781 - val_loss: 0.6619 - val_accuracy: 0.6081\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5402 - accuracy: 0.7158 - val_loss: 0.6516 - val_accuracy: 0.6081\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5455 - accuracy: 0.7021 - val_loss: 0.6626 - val_accuracy: 0.6081\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6200 - accuracy: 0.6301 - val_loss: 0.6319 - val_accuracy: 0.6216\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5731 - accuracy: 0.6712 - val_loss: 0.6610 - val_accuracy: 0.5946\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5606 - accuracy: 0.6849 - val_loss: 0.6362 - val_accuracy: 0.6216\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5436 - accuracy: 0.6884 - val_loss: 0.6340 - val_accuracy: 0.6216\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5346 - accuracy: 0.6884 - val_loss: 0.6701 - val_accuracy: 0.6081\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5522 - accuracy: 0.6747 - val_loss: 0.6512 - val_accuracy: 0.6081\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5511 - accuracy: 0.7021 - val_loss: 0.6249 - val_accuracy: 0.6486\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5423 - accuracy: 0.7055 - val_loss: 0.6686 - val_accuracy: 0.6216\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5395 - accuracy: 0.7021 - val_loss: 0.6675 - val_accuracy: 0.5541\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5249 - accuracy: 0.7158 - val_loss: 0.6661 - val_accuracy: 0.5811\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5048 - accuracy: 0.7363 - val_loss: 0.6770 - val_accuracy: 0.5946\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4990 - accuracy: 0.7295 - val_loss: 0.7177 - val_accuracy: 0.5676\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4960 - accuracy: 0.7158 - val_loss: 0.6847 - val_accuracy: 0.5946\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4902 - accuracy: 0.7123 - val_loss: 0.6966 - val_accuracy: 0.5541\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4668 - accuracy: 0.7432 - val_loss: 0.7166 - val_accuracy: 0.5676\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4651 - accuracy: 0.7329 - val_loss: 0.7507 - val_accuracy: 0.5811\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5020 - accuracy: 0.7397 - val_loss: 0.7299 - val_accuracy: 0.5946\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4883 - accuracy: 0.6986 - val_loss: 0.7349 - val_accuracy: 0.5811\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4761 - accuracy: 0.7500 - val_loss: 0.7628 - val_accuracy: 0.5946\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4821 - accuracy: 0.7192 - val_loss: 0.7938 - val_accuracy: 0.5405\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4907 - accuracy: 0.7089 - val_loss: 0.7131 - val_accuracy: 0.5676\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4397 - accuracy: 0.7774 - val_loss: 0.8225 - val_accuracy: 0.5811\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4576 - accuracy: 0.7466 - val_loss: 0.7450 - val_accuracy: 0.5946\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4438 - accuracy: 0.7568 - val_loss: 0.8595 - val_accuracy: 0.5811\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4651 - accuracy: 0.7808 - val_loss: 0.7154 - val_accuracy: 0.6486\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4544 - accuracy: 0.7295 - val_loss: 0.8441 - val_accuracy: 0.5405\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5018 - accuracy: 0.7295 - val_loss: 0.7196 - val_accuracy: 0.6622\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.4720 - accuracy: 0.7568 - val_loss: 0.7280 - val_accuracy: 0.5811\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.4487 - accuracy: 0.7637 - val_loss: 0.7632 - val_accuracy: 0.6216\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4284 - accuracy: 0.7774 - val_loss: 0.8152 - val_accuracy: 0.5811\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4454 - accuracy: 0.7466 - val_loss: 0.8583 - val_accuracy: 0.5811\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4260 - accuracy: 0.7842 - val_loss: 0.7330 - val_accuracy: 0.5946\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4305 - accuracy: 0.7705 - val_loss: 0.7557 - val_accuracy: 0.5946\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4189 - accuracy: 0.7637 - val_loss: 0.8351 - val_accuracy: 0.6081\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5422 - accuracy: 0.7329 - val_loss: 0.9060 - val_accuracy: 0.6216\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5753 - accuracy: 0.6918 - val_loss: 0.6690 - val_accuracy: 0.5946\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5253 - accuracy: 0.7055 - val_loss: 0.6950 - val_accuracy: 0.5135\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5063 - accuracy: 0.7329 - val_loss: 0.6907 - val_accuracy: 0.5946\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4955 - accuracy: 0.7500 - val_loss: 0.6841 - val_accuracy: 0.5946\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4641 - accuracy: 0.7568 - val_loss: 0.6857 - val_accuracy: 0.6216\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.4408 - accuracy: 0.8014 - val_loss: 0.7151 - val_accuracy: 0.6081\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4328 - accuracy: 0.7740 - val_loss: 0.7516 - val_accuracy: 0.6081\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4252 - accuracy: 0.7945 - val_loss: 0.7437 - val_accuracy: 0.5676\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4251 - accuracy: 0.7740 - val_loss: 0.7227 - val_accuracy: 0.6081\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "fold 2 accracy: 0.5409836065573771\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 44ms/step - loss: 0.6923 - accuracy: 0.5068 - val_loss: 0.6885 - val_accuracy: 0.5676\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6895 - accuracy: 0.5445 - val_loss: 0.6862 - val_accuracy: 0.5676\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6900 - accuracy: 0.5445 - val_loss: 0.6834 - val_accuracy: 0.5676\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6887 - accuracy: 0.5411 - val_loss: 0.6825 - val_accuracy: 0.5676\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6878 - accuracy: 0.5445 - val_loss: 0.6816 - val_accuracy: 0.5676\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6878 - accuracy: 0.5445 - val_loss: 0.6786 - val_accuracy: 0.5676\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6871 - accuracy: 0.5445 - val_loss: 0.6756 - val_accuracy: 0.5676\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6884 - accuracy: 0.5445 - val_loss: 0.6751 - val_accuracy: 0.5676\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6836 - accuracy: 0.5445 - val_loss: 0.6742 - val_accuracy: 0.5676\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.6891 - accuracy: 0.5445 - val_loss: 0.6744 - val_accuracy: 0.5676\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6846 - accuracy: 0.5479 - val_loss: 0.6737 - val_accuracy: 0.5676\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.6840 - accuracy: 0.5514 - val_loss: 0.6714 - val_accuracy: 0.5676\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6827 - accuracy: 0.5719 - val_loss: 0.6744 - val_accuracy: 0.6081\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6831 - accuracy: 0.5753 - val_loss: 0.6737 - val_accuracy: 0.6216\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6823 - accuracy: 0.5822 - val_loss: 0.6700 - val_accuracy: 0.5946\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6801 - accuracy: 0.5685 - val_loss: 0.6717 - val_accuracy: 0.6081\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6866 - accuracy: 0.5548 - val_loss: 0.6714 - val_accuracy: 0.6216\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6777 - accuracy: 0.5788 - val_loss: 0.6682 - val_accuracy: 0.6216\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6819 - accuracy: 0.5788 - val_loss: 0.6614 - val_accuracy: 0.5811\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.6760 - accuracy: 0.5582 - val_loss: 0.6555 - val_accuracy: 0.5946\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6688 - accuracy: 0.6301 - val_loss: 0.6535 - val_accuracy: 0.5946\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6746 - accuracy: 0.5856 - val_loss: 0.6435 - val_accuracy: 0.6081\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6690 - accuracy: 0.5890 - val_loss: 0.6431 - val_accuracy: 0.5811\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.6783 - accuracy: 0.5822 - val_loss: 0.6351 - val_accuracy: 0.6081\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6608 - accuracy: 0.6164 - val_loss: 0.6422 - val_accuracy: 0.6081\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6672 - accuracy: 0.5788 - val_loss: 0.6350 - val_accuracy: 0.5946\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6509 - accuracy: 0.6164 - val_loss: 0.6242 - val_accuracy: 0.5946\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6517 - accuracy: 0.6096 - val_loss: 0.6153 - val_accuracy: 0.6351\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.6301 - val_loss: 0.6427 - val_accuracy: 0.6351\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.5959 - val_loss: 0.6407 - val_accuracy: 0.6216\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6472 - accuracy: 0.6404 - val_loss: 0.6203 - val_accuracy: 0.6216\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6395 - accuracy: 0.6130 - val_loss: 0.6171 - val_accuracy: 0.6216\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6315 - accuracy: 0.6233 - val_loss: 0.6224 - val_accuracy: 0.6081\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6341 - accuracy: 0.6404 - val_loss: 0.6171 - val_accuracy: 0.6081\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6269 - accuracy: 0.6336 - val_loss: 0.6209 - val_accuracy: 0.6216\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6275 - accuracy: 0.6473 - val_loss: 0.6354 - val_accuracy: 0.6081\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6247 - accuracy: 0.6301 - val_loss: 0.6141 - val_accuracy: 0.6216\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6196 - accuracy: 0.6507 - val_loss: 0.6208 - val_accuracy: 0.6216\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6196 - accuracy: 0.6336 - val_loss: 0.6220 - val_accuracy: 0.6216\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6233 - accuracy: 0.6473 - val_loss: 0.6238 - val_accuracy: 0.6216\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6023 - accuracy: 0.6712 - val_loss: 0.6324 - val_accuracy: 0.6216\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6119 - accuracy: 0.6541 - val_loss: 0.6165 - val_accuracy: 0.6351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6065 - accuracy: 0.6438 - val_loss: 0.6198 - val_accuracy: 0.6486\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6125 - accuracy: 0.6404 - val_loss: 0.6183 - val_accuracy: 0.6351\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5946 - accuracy: 0.6541 - val_loss: 0.6253 - val_accuracy: 0.6351\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6085 - accuracy: 0.6610 - val_loss: 0.6306 - val_accuracy: 0.6216\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5948 - accuracy: 0.6267 - val_loss: 0.6372 - val_accuracy: 0.6351\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5833 - accuracy: 0.6747 - val_loss: 0.6195 - val_accuracy: 0.5946\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5868 - accuracy: 0.6678 - val_loss: 0.6513 - val_accuracy: 0.5811\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.5735 - accuracy: 0.6644 - val_loss: 0.6450 - val_accuracy: 0.6351\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5721 - accuracy: 0.6781 - val_loss: 0.6426 - val_accuracy: 0.6351\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.5785 - accuracy: 0.6336 - val_loss: 0.6468 - val_accuracy: 0.6351\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5716 - accuracy: 0.6610 - val_loss: 0.6349 - val_accuracy: 0.6081\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5825 - accuracy: 0.6712 - val_loss: 0.6629 - val_accuracy: 0.6351\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5731 - accuracy: 0.6815 - val_loss: 0.6395 - val_accuracy: 0.6216\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5635 - accuracy: 0.6747 - val_loss: 0.6363 - val_accuracy: 0.5946\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.5630 - accuracy: 0.6712 - val_loss: 0.6286 - val_accuracy: 0.6351\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5435 - accuracy: 0.6849 - val_loss: 0.6606 - val_accuracy: 0.6216\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5402 - accuracy: 0.6712 - val_loss: 0.6768 - val_accuracy: 0.6216\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5558 - accuracy: 0.7021 - val_loss: 0.6746 - val_accuracy: 0.5811\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5571 - accuracy: 0.6541 - val_loss: 0.6625 - val_accuracy: 0.6351\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5369 - accuracy: 0.6610 - val_loss: 0.6918 - val_accuracy: 0.6081\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5294 - accuracy: 0.6918 - val_loss: 0.6782 - val_accuracy: 0.6216\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5170 - accuracy: 0.7021 - val_loss: 0.6591 - val_accuracy: 0.5135\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5255 - accuracy: 0.6747 - val_loss: 0.6412 - val_accuracy: 0.6622\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5452 - accuracy: 0.6747 - val_loss: 0.6815 - val_accuracy: 0.5946\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5592 - accuracy: 0.6781 - val_loss: 0.6714 - val_accuracy: 0.6351\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5363 - accuracy: 0.6884 - val_loss: 0.6868 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5145 - accuracy: 0.6918 - val_loss: 0.6710 - val_accuracy: 0.6351\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5224 - accuracy: 0.6781 - val_loss: 0.6914 - val_accuracy: 0.5676\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5153 - accuracy: 0.6986 - val_loss: 0.6673 - val_accuracy: 0.6486\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5011 - accuracy: 0.6918 - val_loss: 0.6928 - val_accuracy: 0.5541\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4806 - accuracy: 0.7329 - val_loss: 0.6993 - val_accuracy: 0.5676\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4925 - accuracy: 0.7089 - val_loss: 0.7407 - val_accuracy: 0.5811\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5119 - accuracy: 0.6986 - val_loss: 0.6974 - val_accuracy: 0.6486\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4988 - accuracy: 0.7055 - val_loss: 0.6930 - val_accuracy: 0.6081\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4856 - accuracy: 0.7329 - val_loss: 0.6625 - val_accuracy: 0.6486\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4678 - accuracy: 0.6918 - val_loss: 0.7548 - val_accuracy: 0.5811\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4659 - accuracy: 0.7466 - val_loss: 0.7490 - val_accuracy: 0.6216\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4541 - accuracy: 0.7192 - val_loss: 0.7619 - val_accuracy: 0.5946\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4546 - accuracy: 0.7295 - val_loss: 0.8852 - val_accuracy: 0.5405\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4485 - accuracy: 0.7603 - val_loss: 0.8111 - val_accuracy: 0.5541\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4377 - accuracy: 0.7842 - val_loss: 0.7979 - val_accuracy: 0.5811\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4491 - accuracy: 0.7500 - val_loss: 0.7579 - val_accuracy: 0.5676\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4373 - accuracy: 0.7500 - val_loss: 0.8983 - val_accuracy: 0.5270\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5600 - accuracy: 0.6849 - val_loss: 0.7965 - val_accuracy: 0.6351\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5636 - accuracy: 0.6678 - val_loss: 0.7195 - val_accuracy: 0.5676\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5262 - accuracy: 0.6815 - val_loss: 0.6977 - val_accuracy: 0.5541\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4994 - accuracy: 0.7226 - val_loss: 0.6997 - val_accuracy: 0.6351\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4979 - accuracy: 0.7192 - val_loss: 0.7291 - val_accuracy: 0.5676\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4622 - accuracy: 0.7397 - val_loss: 0.7308 - val_accuracy: 0.6081\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4433 - accuracy: 0.7500 - val_loss: 0.7946 - val_accuracy: 0.5270\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4381 - accuracy: 0.7568 - val_loss: 0.7579 - val_accuracy: 0.5541\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4174 - accuracy: 0.7808 - val_loss: 0.7434 - val_accuracy: 0.5946\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4113 - accuracy: 0.7979 - val_loss: 0.7970 - val_accuracy: 0.5676\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4158 - accuracy: 0.7534 - val_loss: 0.8353 - val_accuracy: 0.5405\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4170 - accuracy: 0.7740 - val_loss: 0.8422 - val_accuracy: 0.5811\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4008 - accuracy: 0.7705 - val_loss: 0.8947 - val_accuracy: 0.6081\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4514 - accuracy: 0.7534 - val_loss: 1.0768 - val_accuracy: 0.4865\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4739 - accuracy: 0.7603 - val_loss: 0.8312 - val_accuracy: 0.5811\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "fold 3 accracy: 0.5901639344262295\n",
      "valid_scores: [0.5737704918032787, 0.47540983606557374, 0.5409836065573771, 0.5901639344262295]\n",
      "CV score: 0.5450819672131146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# 時系列分割のためTimeSeriesSplitのインポート\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "valid_scores = []\n",
    "\n",
    "for fold, (train_indices, valid_indices) in enumerate(tscv.split(X_train_np_array)):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, activation='relu', batch_input_shape=(None, X_train_np_array.shape[1], X_train_np_array.shape[2])))\n",
    "    model.add(Dropout(0.6))\n",
    "    '''model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))'''\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #history = model.fit(X_train_np_array, y_train_new, epochs=100, validation_split=0.2, batch_size=64)\n",
    "    history = model.fit(X_train_np_array, y_train_new, epochs=100, validation_split=0.2)\n",
    "    # 予測\n",
    "    y_val_pred = model.predict(X_val_np_array)\n",
    "\n",
    "    # 予測結果の2値化\n",
    "    y_val_pred = np.where(y_val_pred < 0.5, 0, 1)\n",
    "\n",
    "    # 予測精度の算出と表示\n",
    "    score = accuracy_score(y_val_new, y_val_pred)\n",
    "    print(f'fold {fold} accracy: {score}')\n",
    "\n",
    "    # 予測精度スコアをリストに格納\n",
    "    valid_scores.append(score)\n",
    "\n",
    "print(f'valid_scores: {valid_scores}')\n",
    "cv_score = np.mean(valid_scores)\n",
    "print(f'CV score: {cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0d134ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_comp(df):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, activation='relu', batch_input_shape=(None, df.shape[1], df.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e717492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時系列分割のためTimeSeriesSplitのインポート\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# accuracy算出のためaccuracy_scoreのインポート\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96d17707",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 16ms/step - loss: 0.6926 - accuracy: 0.4865\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6796 - accuracy: 0.6081\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6752 - accuracy: 0.6081\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6695 - accuracy: 0.6081\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6708 - accuracy: 0.6081\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6671 - accuracy: 0.6081\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6670 - accuracy: 0.6081\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6712 - accuracy: 0.6081\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6714 - accuracy: 0.6081\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6655 - accuracy: 0.6081\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BFF7F8B5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "fold 0 MAE: 0.4794520547945205\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 0.6982 - accuracy: 0.3946\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6916 - accuracy: 0.5306\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6901 - accuracy: 0.5442\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6894 - accuracy: 0.5442\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6888 - accuracy: 0.5442\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6887 - accuracy: 0.5442\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6869 - accuracy: 0.5442\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6868 - accuracy: 0.5442\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6857 - accuracy: 0.5442\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6840 - accuracy: 0.5442\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BFF951A820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "fold 1 MAE: 0.547945205479452\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 21ms/step - loss: 0.6906 - accuracy: 0.5182\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6902 - accuracy: 0.5455\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6867 - accuracy: 0.5455\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6888 - accuracy: 0.5455\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6856 - accuracy: 0.5455\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6886 - accuracy: 0.5273\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6846 - accuracy: 0.5591\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6834 - accuracy: 0.5682\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6834 - accuracy: 0.5455\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6868 - accuracy: 0.5455\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "fold 2 MAE: 0.5616438356164384\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 3s 22ms/step - loss: 0.6937 - accuracy: 0.5461\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6899 - accuracy: 0.5461\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6870 - accuracy: 0.5461\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6883 - accuracy: 0.5461\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6871 - accuracy: 0.5461\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6862 - accuracy: 0.5461\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6866 - accuracy: 0.5461\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6849 - accuracy: 0.5461\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6855 - accuracy: 0.5427\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6839 - accuracy: 0.5597\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "fold 3 MAE: 0.5616438356164384\n",
      "valid_scores: [0.4794520547945205, 0.547945205479452, 0.5616438356164384, 0.5616438356164384]\n",
      "CV score: 0.5376712328767124\n"
     ]
    }
   ],
   "source": [
    "valid_scores = []\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "for fold, (train_indices, valid_indices) in enumerate(tscv.split(X_train_np_array)):\n",
    "    X_train, X_valid = X_train_np_array[train_indices], X_train_np_array[valid_indices]\n",
    "    y_train, y_valid = y_train_new[train_indices], y_train_new[valid_indices]\n",
    "\n",
    "    # LSTM構築とコンパイル関数にX_trainを渡し、変数modelに代入\n",
    "    model = lstm_comp(X_train)\n",
    "    \n",
    "        # モデル学習\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "    # 予測\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "    # 予測結果の2値化\n",
    "    y_valid_pred = np.where(y_valid_pred < 0.5, 0, 1)\n",
    "\n",
    "    # 予測精度の算出と表示\n",
    "    score = accuracy_score(y_valid, y_valid_pred)\n",
    "    print(f'fold {fold} MAE: {score}')\n",
    "\n",
    "    # 予測精度スコアをリストに格納\n",
    "    valid_scores.append(score)\n",
    "    \n",
    "print(f'valid_scores: {valid_scores}')\n",
    "cv_score = np.mean(valid_scores)\n",
    "print(f'CV score: {cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07fe9940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=4, test_size=None)\n"
     ]
    }
   ],
   "source": [
    "print(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4790e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cc4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as data\n",
    "start = '1965-01-05'\n",
    "end = '2021-10-21'\n",
    "df = data.DataReader('^NKX', 'stooq', start, end)\n",
    "df.to_csv('finance_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ab7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>29152.74</td>\n",
       "      <td>29220.72</td>\n",
       "      <td>28689.05</td>\n",
       "      <td>28708.58</td>\n",
       "      <td>591458200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>29385.95</td>\n",
       "      <td>29489.11</td>\n",
       "      <td>29222.32</td>\n",
       "      <td>29255.55</td>\n",
       "      <td>661082500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>29117.28</td>\n",
       "      <td>29272.49</td>\n",
       "      <td>29076.34</td>\n",
       "      <td>29215.52</td>\n",
       "      <td>576447900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-18</td>\n",
       "      <td>29093.82</td>\n",
       "      <td>29144.33</td>\n",
       "      <td>28925.32</td>\n",
       "      <td>29025.46</td>\n",
       "      <td>625648900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>28787.26</td>\n",
       "      <td>29082.35</td>\n",
       "      <td>28726.22</td>\n",
       "      <td>29068.63</td>\n",
       "      <td>663478700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14141</th>\n",
       "      <td>1965-01-09</td>\n",
       "      <td>1278.32</td>\n",
       "      <td>1278.32</td>\n",
       "      <td>1278.32</td>\n",
       "      <td>1278.32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>1965-01-08</td>\n",
       "      <td>1286.43</td>\n",
       "      <td>1286.43</td>\n",
       "      <td>1286.43</td>\n",
       "      <td>1286.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14143</th>\n",
       "      <td>1965-01-07</td>\n",
       "      <td>1274.27</td>\n",
       "      <td>1274.27</td>\n",
       "      <td>1274.27</td>\n",
       "      <td>1274.27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14144</th>\n",
       "      <td>1965-01-06</td>\n",
       "      <td>1263.99</td>\n",
       "      <td>1263.99</td>\n",
       "      <td>1263.99</td>\n",
       "      <td>1263.99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14145</th>\n",
       "      <td>1965-01-05</td>\n",
       "      <td>1257.72</td>\n",
       "      <td>1257.72</td>\n",
       "      <td>1257.72</td>\n",
       "      <td>1257.72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14146 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Open      High       Low     Close       Volume\n",
       "0      2021-10-21  29152.74  29220.72  28689.05  28708.58  591458200.0\n",
       "1      2021-10-20  29385.95  29489.11  29222.32  29255.55  661082500.0\n",
       "2      2021-10-19  29117.28  29272.49  29076.34  29215.52  576447900.0\n",
       "3      2021-10-18  29093.82  29144.33  28925.32  29025.46  625648900.0\n",
       "4      2021-10-15  28787.26  29082.35  28726.22  29068.63  663478700.0\n",
       "...           ...       ...       ...       ...       ...          ...\n",
       "14141  1965-01-09   1278.32   1278.32   1278.32   1278.32          NaN\n",
       "14142  1965-01-08   1286.43   1286.43   1286.43   1286.43          NaN\n",
       "14143  1965-01-07   1274.27   1274.27   1274.27   1274.27          NaN\n",
       "14144  1965-01-06   1263.99   1263.99   1263.99   1263.99          NaN\n",
       "14145  1965-01-05   1257.72   1257.72   1257.72   1257.72          NaN\n",
       "\n",
       "[14146 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('finance_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cd354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
